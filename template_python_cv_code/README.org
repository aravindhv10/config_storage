* COMMENT work space
#+begin_src emacs-lisp :results silent
  (save-buffer)
  (org-babel-tangle)
  (async-shell-command "./main.unify.sh" "log" "err")
#+end_src

* Main python code

** Find good device and dtype

*** Importing torch
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.import.py
  import torch
#+end_src

*** Main function
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.function.py
  def get_good_device_and_dtype():
      device = "cpu"
      dtype = torch.float32

      if torch.cuda.is_available():
          torch.backends.cudnn.benchmark = True
          device = "cuda:0"
          dtype = torch.float16
          if torch.cuda.get_device_capability()[0] >= 8:
              dtype = torch.bfloat16

      device = torch.device(device)

      return (
          device,
          dtype,
      )
#+end_src

** Code for obtaining and releasing a read lock on a file

*** Import fcntl
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.import.py
  import fcntl
#+end_src

*** Actual function

**** obtain
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.function.py
  def obtain_lock(infd):
      fcntl.flock(
          infd.fileno(),
          fcntl.LOCK_SH,
      )
#+end_src

**** release
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.function.py
  def release_lock(infd):
      fcntl.flock(
          infd.fileno(),
          fcntl.LOCK_UN,
      )
#+end_src

** Function to read images using opencv with locking

*** Import cv2 and numpy
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.import.py
  import cv2
  import numpy as np
#+end_src

*** Read images to torch tensors
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.function.py
  def read_image(path_file_image_input):
      tmpfd = open(
          path_file_image_input,
          "rb",
      )

      obtain_lock(infd=tmpfd)

      image = np.frombuffer(
          tmpfd.read(),
          np.uint8,
      )

      release_lock(infd=tmpfd)
      tmpfd.close()

      image = cv2.imdecode(
          image,
          cv2.IMREAD_COLOR,
      )

      image = cv2.cvtColor(
          src=image,
          code=cv2.COLOR_BGR2RGB,
      )

      return image
#+end_src

** Read normalized image

*** Imports
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.import.py
  import cv2
  import torch
  import albumentations as A
  from albumentations.pytorch import ToTensorV2
  import numpy as np
#+end_src

*** Main class to read the image
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.class.py
  class image_reader:
      def __init__(self):
          self.imagenet_mean = [
              0.485,
              0.456,
              0.406,
          ]

          self.imagenet_std = [
              0.229,
              0.224,
              0.225,
          ]

          self.transform = A.Compose(
              [
                  A.Normalize(
                      mean=self.imagenet_mean,
                      std=self.imagenet_std,
                  ),
                  ToTensorV2(),
              ]
          )

      def read_image(
          self,
          path_file_image_input,
      ):
          image = read_image(path_file_image_input=path_file_image_input)
          transformed_image = self.transform(image=image)["image"]
          return transformed_image

      def __call__(
          self,
          path_file_image_input,
      ):
          return self.read_image(path_file_image_input)
#+end_src

** COMMENT Code to read image and transform to good torch format
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.function.py
  def read_and_normalize_image(image_path):
      """
      Reads an image from the given path, converts it to a PyTorch tensor,
      and normalizes it using ImageNet mean and standard deviation.

      Args:
          image_path (str): The path to the image file.

      Returns:
          torch.Tensor: The normalized image tensor.
      """
      # Define the ImageNet mean and standard deviation
      imagenet_mean = [0.485, 0.456, 0.406]
      imagenet_std = [0.229, 0.224, 0.225]

      # Create an albumentations pipeline
      transform = A.Compose(
          [
              A.Normalize(mean=imagenet_mean, std=imagenet_std),
              ToTensorV2(),
          ]
      )

      # Read the image using OpenCV
      image = cv2.imread(image_path)

      # Convert the image from BGR to RGB format
      image = cv2.cvtColor(
          image,
          cv2.COLOR_BGR2RGB,
      )

      # Apply the transformations
      transformed_image = transform(image=image)["image"]

      return transformed_image
#+end_src

* COMMENT Main code

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.import.py
  import requests
  from PIL import Image
  from io import BytesIO
  from transformers import ViTFeatureExtractor
  from transformers import ViTForImageClassification
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.execute.py
  # Get example image from official fairface repo + read it in as an image
  r = requests.get('https://github.com/dchen236/FairFace/blob/master/detected_faces/race_Asian_face0.jpg?raw=true')
  im = Image.open(BytesIO(r.content))
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.execute.py
  MODEL_NAME = "motheecreator/vit-Facial-Expression-Recognition"
  model = ViTForImageClassification.from_pretrained(MODEL_NAME)
  transforms = ViTFeatureExtractor.from_pretrained(MODEL_NAME)
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.execute.py
  # Transform our image and pass it through the model
  inputs = transforms(im, return_tensors='pt')
  output = model(**inputs)

  # Predicted Class probabilities
  proba = output.logits.softmax(1)

  # Predicted Classes
  preds = proba.argmax(1)
#+end_src

* COMMENT OLD
#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.execute.py
  checkpoint = "google/vit-base-patch16-224-in21k"
  image_processor = AutoImageProcessor.from_pretrained(checkpoint)


  url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
  image = Image.open(requests.get(url, stream=True).raw)

  # processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')
  processor = ViTForImageClassification.from_pretrained('motheecreator/vit-Facial-Expression-Recognition')
  model = ViTForImageClassification.from_pretrained('motheecreator/vit-Facial-Expression-Recognition')
  inputs = processor(images=image, return_tensors="pt")
  outputs = model(**inputs)
#+end_src

* Script to unify

** Important functions

*** Process the python code stream
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
  P () {
      expand | ruff format -
  }
#+end_src

*** Read the python file
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
  R () {
      grep -v '^#!/usr/bin/python3$' "./${1}" | P
  }
#+end_src

*** Remove the python file
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
  C () {
      rm -vf -- "./${1}"
  }
#+end_src

*** Add files to git
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
  A () {
      git add "./${1}"
  }
#+end_src

** Actual working scripts

*** Unifying the python code
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
  (
      echo '#!/usr/bin/env python3'
      R main.config.py
      R main.import.py | sort | uniq
      R main.function.py
      R main.class.py
      R main.execute.py
  ) | P > ./main.py
#+end_src

*** Cleanup residual files
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
  C main.class.py
  C main.config.py
  C main.execute.py
  C main.function.py
  C main.import.py
  C main.unify.sh
#+end_src

*** Add stuff to git
#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
  A main.py
  A README.org
#+end_src

* Sample

#+begin_src sh :shebang #!/bin/sh :results output :tangle ./main.unify.sh
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.config.py
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.import.py
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.function.py
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.class.py
#+end_src

#+begin_src python :shebang #!/usr/bin/python3 :results output :tangle ./main.execute.py
#+end_src
